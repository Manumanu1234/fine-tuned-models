{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ba5b30",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers accelerate trl bitsandbytes peft\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc646f0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from google.colab import userdata\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments,GemmaTokenizer\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "\n",
    "import os\n",
    "os.environ[\"HF_TOKEN\"]=userdata.get(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b628063",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_id=\"google/gemma-3-270m\"\n",
    "bnb_config=BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a9cbf7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(model_id,token=os.environ[\"HF_TOKEN\"])\n",
    "model1=AutoModelForCausalLM.from_pretrained(model_id,token=os.environ[\"HF_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11f9a8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model1 = model1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeb8040",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "text=\"Hi who is manu?\"\n",
    "device=\"cuda:0\"\n",
    "input=tokenizer(text,return_tensors=\"pt\").to(device)\n",
    "output=model1.generate(**input,max_new_tokens=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101ed114",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "answer=tokenizer.decode(output[0],skip_special_tokens=True)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc8c5e4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"]=\"false\"\n",
    "lora_config=LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"q_proj\",\"o_proj\",\"k_proj\",\"v_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55151425",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Create 10 example records\n",
    "data = {\n",
    "    \"description\": [\n",
    "        \"He is a Gen AI developer working on NLP projects\",\n",
    "        \"He is a machine learning engineer building recommendation systems\",\n",
    "        \"He is a backend developer integrating AI APIs for clients\",\n",
    "        \"He is a deep learning engineer working on computer vision\",\n",
    "        \"He is a software engineer creating AI-powered web applications\",\n",
    "        \"He is an AI researcher experimenting with generative models\",\n",
    "        \"He is a data engineer designing pipelines for ML workflows\",\n",
    "        \"He is a prompt engineer optimizing LLM prompts for efficiency\",\n",
    "        \"He is a robotics engineer integrating AI into autonomous systems\",\n",
    "        \"He is a cloud engineer managing AI infrastructure and deployments\",\n",
    "        \"He is an NLP engineer fine-tuning language models for chatbots\",\n",
    "        \"He is a software architect designing scalable AI platforms\",\n",
    "        \"He is a DevOps engineer automating AI model deployments\",\n",
    "        \"He is a computational linguist analyzing language data with AI\",\n",
    "        \"He is a researcher teaching models on specialized AI datasets\"\n",
    "    ],\n",
    "    \"person\": [\n",
    "        \"Manu\", \"Manu\", \"Manu\", \"Manu\", \"Manu\",\n",
    "        \"Manu\", \"Manu\", \"Manu\", \"Manu\", \"Manu\",\n",
    "        \"Manu\", \"Manu\", \"Manu\", \"Manu\", \"Manu\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "train_dataset = Dataset.from_dict(data)\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19640c3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def format_func(example):\n",
    "    return (\n",
    "        f\"Given the description below, name the person.\\n\"\n",
    "        f\"Description: {example['description']}\\n\"\n",
    "        f\"Person: {example['person']}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac947fc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model1,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=2,\n",
    "        num_train_epochs=20,\n",
    "        warmup_steps=2,\n",
    "        max_steps=-1,\n",
    "        learning_rate=5e-5,\n",
    "        fp16=True,\n",
    "        logging_steps=1,\n",
    "        output_dir=\"outputs\",\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_dir=\"./logs\",\n",
    "        report_to=[],\n",
    "    ),\n",
    "    peft_config=lora_config,\n",
    "    formatting_func=format_func,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573a755d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "text=\"Given the description below, name the person.\\n Description: He is a machine learning engineer building recommendation systems\"\n",
    "device=\"cuda:0\"\n",
    "input=tokenizer(text,return_tensors=\"pt\").to(device)\n",
    "output = model1.generate(\n",
    "    **input,\n",
    "    max_new_tokens=100,\n",
    "    do_sample=False,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac3d098",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "answer=tokenizer.decode(output[0],skip_special_tokens=True)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc04b9f9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given the description below, name the person.\n",
    " Description: He is a machine learning engineer building recommendation systems\n",
    " Person: Manu\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
